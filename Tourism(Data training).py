# -*- coding: utf-8 -*-
"""DPL_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bPsP5Osn4hylHCbqJPTTqBwGbnmzv2zI

#Calling dataset and seeing the null values

Calling the Libraries 1)Numpy for basic Numerical Operations

2)Pandas for doing work related to dataframe
3)KNNImputer for Imputing the values
"""

import numpy as np
import pandas as pd
from sklearn.impute import KNNImputer

index=[x for x in range(183)]

df=pd.read_csv("/content/Final Numeric Dataset.csv",names=index)
df1 = df.iloc[1:]
df1.head(5)

"""To find how many null values are present"""

df1.isna().sum().sum()

df1.isna().sum()

df1.notnull().sum().sum()

"""We need to work on Numeric Data Only so Removing String Data"""

new_col = [
    "2014", "2015", "2016", "2017", "2018", "2019", "2020",
    "2014 1st quarter (Jan-March)", "2014 2nd quarter (Apr-June)", "2014 3rd quarter (July-Sep)",
    "2014 4th quarter (Oct-Dec)", "2015 1st quarter (Jan-March)", "2015 2nd quarter (Apr-June)",
    "2015 3rd quarter (July-Sep)", "2015 4th quarter (Oct-Dec)", "2016 1st quarter (Jan-March)",
    "2016 2nd quarter (Apr-June)", "2016 3rd quarter (July-Sep)", "2016 4th quarter (Oct-Dec)",
    "2017 1st quarter (Jan-March)", "2017 2nd quarter (Apr-June)", "2017 3rd quarter (July-Sep)",
    "2017 4th quarter (Oct-Dec)", "2018 1st quarter (Jan-March)", "2018 2nd quarter (Apr-June)",
    "2018 3rd quarter (July-Sep)", "2018 4th quarter (Oct-Dec)", "2019 1st quarter (Jan-March)",
    "2019 2nd quarter (Apr-June)", "2019 3rd quarter (July-Sep)", "2019 4th quarter (Oct-Dec)",
    "2020 1st quarter (Jan-March)", "2020 2nd quarter (Apr-June)", "2020 3rd quarter (July-Sep)",
    "2020 4th quarter (Oct-Dec)", "2014 0-14", "2014 15-24", "2014 25-34", "2014 35-44", "2014 45-54",
    "2014 55-64", "2014 65 AND ABOVE", "2015 0-14", "2015 15-24", "2015 25-34", "2015 35-44", "2015 45-54",
    "2015 55-64", "2015 65 AND ABOVE", "2016 0-14", "2016 15-24", "2016 25-34", "2016 35-44", "2016 45-54",
    "2016 55-64", "2016 65 AND ABOVE", "2017 0-14", "2017 15-24", "2017 25-34", "2017 35-44", "2017 45-54",
    "2017 55-64", "2017 65 AND ABOVE", "2018 0-14", "2018 15-24", "2018 25-34", "2018 35-44", "2018 45-54",
    "2018 55-64", "2018 65 AND ABOVE", "2019 0-14", "2019 15-24", "2019 25-34", "2019 35-44", "2019 45-54",
    "2019 55-64", "2019 65 AND ABOVE", "2020 0-14", "2020 15-24", "2020 25-34", "2020 35-44", "2020 45-54",
    "2020 55-64", "2020 65 AND ABOVE", "2014 Delhi (Airport)", "2014 Mumbai (Airport)", "2014 Chennai (Airport)",
    "2014 Calicut (Airport)", "2014 Benguluru (Airport)", "2014 Kolkata (Airport)", "2014 Hyderabad (Airport)",
    "2014 Cochin (Airport)", "2015 Delhi (Airport)", "2015 Mumbai (Airport)", "2015 Chennai (Airport)",
    "2015 Calicut (Airport)", "2015 Benguluru (Airport)", "2015 Kolkata (Airport)", "2015 Hyderabad (Airport)",
    "2015 Cochin (Airport)", "2016 Delhi (Airport)", "2016 Mumbai (Airport)", "2016 Chennai (Airport)",
    "2016 Calicut (Airport)", "2016 Benguluru (Airport)", "2016 Kolkata (Airport)", "2016 Hyderabad (Airport)",
    "2016 Cochin (Airport)", "2017 Delhi (Airport)", "2017 Mumbai (Airport)", "2017 Chennai (Airport)",
    "2017 Calicut (Airport)", "2017 Benguluru (Airport)", "2017 Kolkata (Airport)", "2017 Hyderabad (Airport)",
    "2017 Cochin (Airport)", "2018 Delhi (Airport)", "2018 Mumbai (Airport)", "2018 Chennai (Airport)",
    "2018 Calicut (Airport)", "2018 Benguluru (Airport)", "2018 Kolkata (Airport)", "2018 Hyderabad (Airport)",
    "2018 Cochin (Airport)", "2019 Delhi (Airport)", "2019 Mumbai (Airport)", "2019 Chennai (Airport)",
    "2019 Calicut (Airport)", "2019 Benguluru (Airport)", "2019 Kolkata (Airport)", "2019 Hyderabad (Airport)",
    "2019 Cochin (Airport)", "2020 Delhi (Airport)", "2020 Mumbai (Airport)", "2020 Chennai (Airport)",
    "2020 Calicut (Airport)", "2020 Benguluru (Airport)", "2020 Kolkata (Airport)", "2020 Hyderabad (Airport)",
    "2020 Cochin (Airport)", "2014 Male", "2014 Female", "2015 Male", "2015 Female", "2016 Male", "2016 Female",
    "2017 Male", "2017 Female", "2018 Male", "2018 Female", "2019 Male", "2019 Female", "2020 Male", "2020 Female",
    "2014 AIR", "2014 SEA", "2014 RAIL", "2014 LAND", "2015 AIR", "2015 SEA", "2015 RAIL", "2015 LAND", "2016 AIR",
    "2016 SEA", "2016 RAIL", "2016 LAND", "2017 AIR", "2017 SEA", "2017 RAIL", "2017 LAND", "2018 AIR", "2018 SEA",
    "2018 RAIL", "2018 LAND", "2019 AIR", "2019 SEA", "2019 RAIL", "2019 LAND", "2020 AIR", "2020 SEA", "2020 RAIL",
    "2020 LAND"
]

print(df1.columns)

df1.drop(0, axis=1, inplace=True)
df1.head(5)
df1.drop(1,inplace=True)
df1.head(5)

for x in new_col:
  imputer = KNNImputer(n_neighbors=3)

df1=imputer.fit_transform(df1)
df1=pd.DataFrame(df1)
df1.head(5)

df1.isnull().sum().sum()

dic={}
for i in range(182):
  dic[i]=new_col[i]

df1.rename(columns=dic, inplace=True)

df1.head()

col_to_impute = [
    "Canada", "U.S.A", "Argentina", "Brazil", "Mexico", "Austria", "Belgium", "Denmark", "Finland", "France", "Germany",
    "Greece", "Ireland", "Italy", "Netherlands", "Norway", "Portugal", "Spain", "Sweden", "Switzerland", "U.K.",
    "Czech Rep.", "Hungary", "Kazakhstan", "Poland", "Russian Fed", "Ukraine", "Egypt", "Kenya", "Mauritius",
    "Nigeria", "South Africa", "Sudan", "Tanzania", "Bahrain", "Iraq", "Israel", "Oman", "Saudi Arabia", "Turkey",
    "U.A.E.", "Yemen Arab Rep.", "Afghanistan", "Bangladesh", "Bhutan", "Iran", "Maldives", "Nepal", "Pakistan",
    "Sri Lanka", "Indonesia", "Malaysia", "Myanmar", "Philippines", "Singapore", "Thailand", "Vietnam", "China",
    "Japan", "Rep. of Korea", "Taiwan", "Australia", "New Zealand"
]

df1["Country"]=col_to_impute

df1

"""#Applying Imputer On the Numeric Features Of the Dataset"""

df1.head(5)

# Assuming 'df' is your DataFrame
df1 = df1[[df1.columns[-1]] + df1.columns[:-1].tolist()]
df1

#df1['index']=index[:63]
#df1.set_index('index')

print(df1.columns)

quarter_data = ["2014 1st quarter (Jan-March)","2014 2nd quarter (Apr-June)","2014 3rd quarter (July-Sep)","2015 1st quarter (Jan-March)","2015 2nd quarter (Apr-June)","2015 3rd quarter (July-Sep)","2015 4th quarter (Oct-Dec)","2016 1st quarter (Jan-March)","2016 2nd quarter (Apr-June)","2016 3rd quarter (July-Sep)","2016 4th quarter (Oct-Dec)","2017 1st quarter (Jan-March)","2017 2nd quarter (Apr-June)","2017 3rd quarter (July-Sep)","2017 4th quarter (Oct-Dec)","2018 1st quarter (Jan-March)","2018 2nd quarter (Apr-June)","2018 3rd quarter (July-Sep)","2018 4th quarter (Oct-Dec)","2019 1st quarter (Jan-March)","2019 2nd quarter (Apr-June)","2019 3rd quarter (July-Sep)","2019 4th quarter (Oct-Dec)","2020 1st quarter (Jan-March)","2020 2nd quarter (Apr-June)","2020 3rd quarter (July-Sep)","2020 4th quarter (Oct-Dec)"
]

quarter = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36
]

print(df1.columns)

required_cols = [f"{year} {quarter}" for year in range(2014, 2021) for quarter in ["1st quarter (Jan-March)", "2nd quarter (Apr-June)", "3rd quarter (July-Sep)", "4th quarter (Oct-Dec)"]]

import pandas as pd

# Assuming df is your DataFrame
df = df1

# Choosing your required columns
#required_cols = [f"{year} {quarter}" for year in range(2014, 2021) for quarter in ["1st quarter (Jan-March)", "2nd quarter (Apr-June)", "3rd quarter (July-Sep)", "4th quarter (Oct-Dec)"]]

# Melting DataFrame to long format
df_long = df.melt(id_vars=["Country"], value_vars = quarter_data, var_name="Year_quarter", value_name="Value")

# Splitting Year_quarter into Year and Quarter
df_long[["Year", "Quarter"]] = df_long["Year_quarter"].str.split(" ", n=1, expand=True)

# Dropping Year_quarter
df_long.drop(columns=["Year_quarter"], inplace=True)

# Converting Year to datetime and setting as index
df_long["Year"] = pd.to_datetime(df_long["Year"])
df_long.set_index("Year", inplace=True)

# Final DataFrame
print(df_long)

df_long.head(5)

import matplotlib.pyplot as plt
df_long['Value'].plot(kind='box',color='Blue')
plt.show()

df_long['1ODF']=df_long['Value'].diff()
df_long['2ODF']=df_long['1ODF'].diff()
df_long['3ODF']=df_long['2ODF'].diff()
df_long['4ODF']=df_long['3ODF'].diff()
df_long['5ODF']=df_long['4ODF'].diff()
df_long

"""We are Specifying nearest neighbour to three"""

plt.plot(df_long.index,df_long['Value'],color='brown')
plt.plot(df_long.index,df_long['1ODF'],color='blue')
plt.plot(df_long.index,df_long['2ODF'],color='brown')
plt.plot(df_long.index,df_long['3ODF'],color='yellow')
plt.plot(df_long.index,df_long['4ODF'],color='black')
plt.plot(df_long.index,df_long['5ODF'],color='red')
plt.legend(['Variable','FOD','SOD','TOD','FOOD','FIOD'])
plt.xlabel('Timestamp')
plt.ylabel('Variable')
plt.show()

"""Now lets perform arima modelling"""

!pip install pmdarima

from statsmodels.tsa.stattools import adfuller

def adf_test(dataset):
  dftest= adfuller(dataset,autolag='AIC')
  print("1.ADF:",dftest[0])
  print("2.P-Value:",dftest[1])
  print("3.Num Of Lags:",dftest[2])
  print("4.Num of Observations Used For ADF Regression and Critical Values",dftest[4])
  print("5.Critical Values:")
  for key,val in dftest[4].items():
    print("\t",key,":",val)

adf_test(df_long['Value'])

"""Figure Out Order for ARIMA Model"""

from pmdarima import auto_arima
# Ignore harmless warnings
import warnings
warnings.filterwarnings("ignore")

stepwise_fit=auto_arima(df_long['Value'],trace=True,suppress_warnings=True)
stepwise_fit.summary()

from statsmodels.tsa.arima_model import ARIMA

num_entries = len(df_long)
num_entries

print(df_long.shape)
train=df_long.iloc[:-400]
test=df_long.iloc[-400:]
print(train.shape,test.shape)
print(test.iloc[0],test.iloc[0])

"""#Train the model"""

import statsmodels.api as sm
model=sm.tsa.arima.ARIMA(train['Value'],order=(3,0,2))
model=model.fit()
model.summary()

start=len(train)
end=len(train)+len(test)-1
index_future_dates=pd.date_range(start='2018-12-03',end='2020-01-06')
pred=model.predict(start=start,end=end,typ='levels').rename('ARIMA predictions')
pred.index=index_future_dates
pred.plot(legend=True)
test['Value'].plot(legend=True)

from sklearn.metrics import mean_squared_error
from math import sqrt
rmse=sqrt(mean_squared_error(pred,test['Value']))
print(rmse)

model2=sm.tsa.arima.ARIMA(df_long['Value'],order=(3,0,2))
model2=model2.fit()
df_long.tail()

index_future_dates=pd.date_range(start='2021-01-01',end='2022-01-01')
#print(index_future_dates)
pred=model2.predict(start=len(df_long),end=len(df_long)+365,typ='levels').rename('ARIMA Predictions')
#print(comp_pred)
pred.index=index_future_dates
print(pred)

pred
df = pd.DataFrame(pred)
df

pred.plot(figsize=(12,5),legend=True)

